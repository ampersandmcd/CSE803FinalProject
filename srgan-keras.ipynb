{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-08T14:37:12.973659Z","iopub.execute_input":"2021-12-08T14:37:12.973966Z","iopub.status.idle":"2021-12-08T14:37:13.018684Z","shell.execute_reply.started":"2021-12-08T14:37:12.973884Z","shell.execute_reply":"2021-12-08T14:37:13.018000Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 2.explore","metadata":{}},{"cell_type":"markdown","source":"## to activate the gpu and address the args parser issue  https://stackoverflow.com/questions/48796169/how-to-fix-ipykernel-launcher-py-error-unrecognized-arguments-in-jupyter","metadata":{}},{"cell_type":"code","source":"import xarray","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:37:29.172419Z","iopub.execute_input":"2021-12-08T14:37:29.172688Z","iopub.status.idle":"2021-12-08T14:37:31.930026Z","shell.execute_reply.started":"2021-12-08T14:37:29.172659Z","shell.execute_reply":"2021-12-08T14:37:31.929315Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n\ndef visualize(data, year, month, variable, save=False):\n    if variable == \"t2m\":\n        img = data.t2m[12*(year - 1950) + month - 1]\n        name = \"Surface Temperature\"\n        cmap = \"RdYlBu_r\"\n    elif variable == \"tp\":\n        img = data.tp[12*(year - 1950) + month - 1]\n        name = \"Total Precipitation\"\n        cmap = \"BrBG\"\n    else:\n        raise ValueError(\"Invalid variable.\")\n    fig, ax = plt.subplots(figsize=(8, 3.5))\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes('right', size='5%', pad=0.05)\n    divnorm = colors.TwoSlopeNorm(vmin=img.min(), vcenter=img.mean(), vmax=img.max())\n    mapping = ax.imshow(img, cmap=cmap, norm=divnorm)\n    fig.colorbar(mapping, cax=cax)\n    ax.set_title(f\"ERA5 {name} ({month}/{year})\")\n    plt.tight_layout()\n    if save:\n        plt.savefig(f\"figs/{variable}_{year}_{month}.png\")\n    plt.show()\n\n\ndef visualize_patches(data, year, month, variable, size=64, save=False):\n    if variable == \"t2m\":\n        img = data.t2m[12*(year - 1950) + month - 1]\n        name = \"Surface Temperature\"\n        cmap = \"RdYlBu_r\"\n    elif variable == \"tp\":\n        img = data.tp[12*(year - 1950) + month - 1]\n        name = \"Total Precipitation\"\n        cmap = \"BrBG\"\n    else:\n        raise ValueError(\"Invalid variable.\")\n    n_vertical, n_horizontal = img.shape[0] // size, img.shape[1] // size\n    fig = plt.figure(figsize=(8, 4))\n    gs = fig.add_gridspec(n_vertical, n_horizontal + 1, width_ratios=[1 for i in range(n_horizontal)] + [0.1])\n    min_, mean_, max_ = img.min(), img.mean(), img.max()\n    divnorm = colors.TwoSlopeNorm(vmin=min_, vcenter=mean_, vmax=max_)\n    for i in range(n_vertical):\n        for j in range(n_horizontal):\n            ax = fig.add_subplot(gs[i, j])\n            patch = img[i*size:(i+1)*size, j*size:(j+1)*size]\n            mapping = ax.imshow(patch, norm=divnorm, cmap=cmap)\n            ax.axis(\"off\")\n            ax.set_title(f\"{i*size}:{(i+1)*size}, {j*size}:{(j+1)*size}\", fontsize=6)\n    cax = fig.add_subplot(gs[:, -1])\n    fig.colorbar(mapping, cax=cax)\n    fig.suptitle(f\"ERA5 {name} ({month}/{year}) Patches {size}x{size}\")\n    plt.tight_layout()\n    if save:\n        plt.savefig(f\"figs/{variable}_{year}_{month}_patches.png\")\n    plt.show()\n\n\ndef visualize_pool(data, year, month, variable, row, col, pool=4, size=64, save=False):\n\n    if variable == \"t2m\":\n        img = data.t2m[12*(year - 1950) + month - 1]\n        name = \"Surface Temperature\"\n        cmap = \"RdYlBu_r\"\n    elif variable == \"tp\":\n        img = data.tp[12*(year - 1950) + month - 1]\n        name = \"Total Precipitation\"\n        cmap = \"BrBG\"\n    else:\n        raise ValueError(\"Invalid variable.\")\n\n    # extract patch and set up figure\n    img = img[row:row+size, col:col+size]\n    fig = plt.figure(figsize=(8, 4))\n    gs = fig.add_gridspec(1, 3, width_ratios=[1, 1, 0.1])\n    min_, mean_, max_ = img.min(), img.mean(), img.max()\n    divnorm = colors.TwoSlopeNorm(vmin=min_, vcenter=mean_, vmax=max_)\n\n    # plot original patch\n    ax = fig.add_subplot(gs[0])\n    ax.axis(\"off\")\n    mapping = ax.imshow(img, norm=divnorm, cmap=cmap)\n\n    # create downsampled patch of same dimension\n    downsampled = img.values.reshape(size//pool, pool, size//pool, pool).mean(axis=(1, 3))\n    upsampled = np.repeat(np.repeat(downsampled, pool, axis=0), pool, axis=1)\n\n    # plot downsampled patch\n    ax = fig.add_subplot(gs[1])\n    ax.axis(\"off\")\n    ax.imshow(downsampled, norm=divnorm, cmap=cmap)\n\n    # plot colorbar\n    cax = fig.add_subplot(gs[2])\n    fig.colorbar(mapping, cax=cax)\n    fig.suptitle(f\"ERA5 {name} ({month}/{year}) Patch {size}x{size} at ({row},{col}) Pooled {pool}x\")\n    plt.tight_layout()\n    if save:\n        plt.savefig(f\"figs/{variable}_{year}_{month}_pool_{pool}_{row}_{col}.png\")\n    plt.show()\n\n\n\ndef visualize_nan(data, year, month, variable, row, col, pool=4, size=64, save=False):\n    if variable == \"t2m\":\n        img = data.t2m[12 * (year - 1950) + month - 1]\n        name = \"Surface Temperature\"\n        cmap = \"RdYlBu_r\"\n    elif variable == \"tp\":\n        img = data.tp[12 * (year - 1950) + month - 1]\n        name = \"Total Precipitation\"\n        cmap = \"BrBG\"\n    else:\n        raise ValueError(\"Invalid variable.\")\n\n        # extract patch and set up figure\n    img = img[row:row + size, col:col + size]\n    fig = plt.figure(figsize=(8, 4))\n    gs = fig.add_gridspec(1, 3, width_ratios=[1, 1, 0.1])\n    min_, mean_, max_ = img.min(), img.mean(), img.max()\n    divnorm = colors.TwoSlopeNorm(vmin=min_, vcenter=mean_, vmax=max_)\n\n    # plot original patch\n    ax = fig.add_subplot(gs[0])\n    ax.axis(\"off\")\n    mapping = ax.imshow(img, norm=divnorm, cmap=cmap)\n\n    # create nan-replaced patch of same dimension\n    replacement = np.nanmean(img)\n    img = np.nan_to_num(img, nan=replacement)\n\n    # plot nan-fixed patch\n    ax = fig.add_subplot(gs[1])\n    ax.axis(\"off\")\n    ax.imshow(img, norm=divnorm, cmap=cmap)\n\n    # plot colorbar\n    cax = fig.add_subplot(gs[2])\n    fig.colorbar(mapping, cax=cax)\n    fig.suptitle(f\"ERA5 {name} ({month}/{year}) Patch {size}x{size} at ({row},{col}) Pooled {pool}x\")\n    plt.tight_layout()\n    if save:\n        if not os.path.exists(f\"./figs\"):\n            os.makedirs(f\"./figs\")\n        plt.savefig(f\"./figs/nan_{variable}_{year}_{month}_pool_{pool}_{row}_{col}.png\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    data = xr.open_dataset(f\"../input/era5-dataset/era5.nc\")\n    # visualize(data, 2020, 4, \"t2m\", save=True)\n    # visualize(data, 2020, 4, \"tp\", save=True)\n    # visualize_patches(data, 2020, 4, \"t2m\", size=64, save=True)\n    # visualize_patches(data, 2020, 4, \"tp\", size=64, save=True)\n    # visualize_pool(data, 2020, 4, \"t2m\", row=64, col=128, size=64, pool=4, save=True)\n    # visualize_pool(data, 2020, 4, \"tp\", row=64, col=128, size=64, pool=4, save=True)\n    visualize_nan(data, 2020, 4, \"t2m\", row=0, col=0, size=64, pool=4, save=True)\n    visualize_nan(data, 2020, 4, \"tp\", row=0, col=0, size=64, pool=4, save=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:37:31.931804Z","iopub.execute_input":"2021-12-08T14:37:31.932063Z","iopub.status.idle":"2021-12-08T14:37:33.368085Z","shell.execute_reply.started":"2021-12-08T14:37:31.932012Z","shell.execute_reply":"2021-12-08T14:37:33.367320Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 3. NN MODEL\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pytorch_lightning as pl\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n\n\nclass BaseModel(pl.LightningModule):\n    def __init__(\n            self,\n            input_channels: list = [0, 1],      # indices of tensor input channels to consider (0=t2m, 1=tp)\n            output_channels: list = [0, 1],     # indices of tensor target channels to predict (0=t2m, 1=tp)\n            lr: float = 1e-3,\n            decayRate = 1\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.learning_rate = lr\n        self.input_channels = input_channels\n        self.output_channels = output_channels\n        self.input_dim = len(input_channels)\n        self.output_dim = len(output_channels)\n        self.exp_decay_rate = decayRate\n\n    def training_step(self, batch, batch_idx):\n        x = batch['x'][:, self.input_channels, :, :]\n        y = batch['y'][:, self.output_channels, :, :]\n        y_hat = self(x)\n        loss = F.mse_loss(y_hat, y)\n        self.log('train_loss', loss)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x = batch['x'][:, self.input_channels, :, :]\n        y = batch['y'][:, self.output_channels, :, :]\n        y_hat = self(x)\n        loss = F.mse_loss(y_hat, y)\n        self.log('val_loss', loss)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        x = batch['x'][:, self.input_channels, :, :]\n        y = batch['y'][:, self.output_channels, :, :]\n        y_hat = self(x)\n\n        def _ssim_trans(x):\n            return x.detach().cpu().permute(0, 2, 3, 1).numpy()\n\n        def _psnr_trans(x):\n            x_ = x.detach().cpu().numpy()\n            min_ = np.amin(x_)\n            max_ = np.amax(x_)\n            return (x_ - min_) / (max_ - min_)\n\n        self.log_dict({\n            'MSE': F.mse_loss(y_hat, y),\n            'SSIM': ssim(_ssim_trans(y_hat), _ssim_trans(y), multichannel=True),\n            'PSNR': psnr(image_true=_psnr_trans(y), image_test=_psnr_trans(y_hat), data_range=1)\n        })\n\n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return {\n            'optimizer': opt,\n            'lr_scheduler': torch.optim.lr_scheduler.ExponentialLR(opt, self.exp_decay_rate)\n        }\n\n\n\nclass SRCNN(BaseModel):\n    \"\"\"\n    Image Super-Resolution Using Deep Convolutional Networks\n    Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang\n    https://arxiv.org/pdf/1501.00092.pdf\n    \"\"\"\n    def __init__(\n            self,\n            hidden_1: int = 64,     # n_1 in the paper\n            hidden_2: int = 32,     # n_2 in the paper\n            kernel_1: int = 9,      # f_1\n            kernel_2: int = 1,      # f_2\n            kernel_3: int = 5,      # f_3\n            padding: bool = True,\n            **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.hidden_1 = hidden_1\n        self.hidden_2 = hidden_2\n        self.kernel_1 = kernel_1\n        self.kernel_2 = kernel_2\n        self.kernel_3 = kernel_3\n        self.padding = padding\n\n        extra_args = {}\n        if self.padding:\n            extra_args[\"padding\"] = \"same\"\n            extra_args[\"padding_mode\"] = \"replicate\"\n\n        self.layers = nn.Sequential(\n            nn.Conv2d(in_channels=self.input_dim, out_channels=self.hidden_1, kernel_size=self.kernel_1, **extra_args),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=self.hidden_1, out_channels=self.hidden_2, kernel_size=self.kernel_2, **extra_args),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=self.hidden_2, out_channels=self.output_dim, kernel_size=self.kernel_3, **extra_args),\n        )\n\n    def training_step(self, batch, batch_idx):\n        x = batch['x'][:, self.input_channels, :, :]\n        y = batch['y'][:, self.output_channels, :, :]\n        y_hat = self(x)    \n        loss = F.mse_loss(y_hat, y)\n        self.log('train_loss', loss)\n        return loss\n        \n    def forward(self, x):\n        return self.layers(x)\n\n\nclass VDSR(BaseModel):\n    \"\"\"\n    Accurate Image Super-Resolution Using Very Deep Convolutional Networks\n    Jiwon Kim, Jung Kwon Lee and Kyoung Mu Lee\n    https://arxiv.org/pdf/1511.04587.pdf\n    \"\"\"\n    def __init__(\n            self,\n            d: int = 20,                # d=20 in the paper\n            kernel: int = 3,            # k=3 in the paper\n            hidden_dim: int = 64,       # hidden_dim=64 in the paper\n            pre_post_kernel: int = 9,   # not in paper, but we draw inspiration from SRCNN and SRResNet\n            **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.d = d\n        self.kernel = kernel\n        self.hidden_dim = hidden_dim\n        self.pre_post_kernel = pre_post_kernel\n\n        # construct layer before blocks\n        pre_layers = [\n            nn.Conv2d(in_channels=self.input_dim, out_channels=self.hidden_dim, kernel_size=self.pre_post_kernel, padding=\"same\", padding_mode=\"replicate\"),\n            nn.ReLU()\n        ]\n        self.pre_layers = nn.Sequential(*pre_layers)\n\n        # construct main set of blocks\n        blocks = []\n        for _ in range(d-2):\n            blocks.append(nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.hidden_dim, kernel_size=self.kernel, padding=\"same\", padding_mode=\"replicate\"))\n            blocks.append(nn.ReLU())\n        self.blocks = nn.Sequential(*blocks)\n\n        # construct layer after blocks and residual connection\n        post_layers = [\n            nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.output_dim, kernel_size=self.pre_post_kernel, padding=\"same\", padding_mode=\"replicate\"),\n        ]\n        self.post_layers = nn.Sequential(*post_layers)\n\n    def forward(self, x):\n        x = self.pre_layers(x)  # preprocess input to hidden_dim x h x w\n        x = x + self.blocks(x)  # apply post-block skip connection\n        x = self.post_layers(x)     # postprocess back to c x h x w\n        return x\n\n\nclass SRResNet(BaseModel):\n    \"\"\"\n    Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n    Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, ´\n    Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\n    https://openaccess.thecvf.com/content_cvpr_2017/papers/Ledig_Photo-Realistic_Single_Image_CVPR_2017_paper.pdf\n    \"\"\"\n    def __init__(\n            self,\n            n_blocks: int = 16,         # n_blocks=16 in the paper\n            kernel: int = 3,            # k=3 in the paper\n            pre_post_kernel: int = 9,   # pre_post_kernel=9 in the paper\n            hidden_dim: int = 64,       # hidden_dim=64 in the paper\n            **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.n_blocks = n_blocks\n        self.kernel = kernel\n        self.pre_post_kernel = pre_post_kernel\n        self.hidden_dim = hidden_dim\n\n        # construct layers before residual blocks\n        pre_layers = [\n            nn.Conv2d(in_channels=self.input_dim, out_channels=self.hidden_dim, kernel_size=self.pre_post_kernel, padding=\"same\", padding_mode=\"replicate\"),\n            nn.PReLU()\n        ]\n        self.pre_layers = nn.Sequential(*pre_layers)\n\n        # construct residual blocks\n        blocks = []\n        for _ in range(n_blocks):\n            block = [\n                nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.hidden_dim, kernel_size=self.kernel, padding=\"same\", padding_mode=\"replicate\"),\n                nn.BatchNorm2d(num_features=self.hidden_dim),\n                nn.PReLU(),\n                nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.hidden_dim, kernel_size=self.kernel, padding=\"same\", padding_mode=\"replicate\"),\n                nn.BatchNorm2d(num_features=self.hidden_dim)\n            ]\n            block = nn.Sequential(*block)\n            blocks.append(block)\n        self.blocks = nn.ModuleList(blocks)\n\n        # construct layers after residual blocks, before last residual connection\n        post_layers_1 = [\n            nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.hidden_dim, kernel_size=self.kernel, padding=\"same\", padding_mode=\"replicate\"),\n            nn.BatchNorm2d(num_features=self.hidden_dim)\n        ]\n        self.post_layers_1 = nn.Sequential(*post_layers_1)\n\n        # construct layers after residual blocks, after last residual connection\n        post_layers_2 = [\n            nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.hidden_dim, kernel_size=self.kernel, padding=\"same\", padding_mode=\"replicate\"),\n            nn.PReLU(),\n            nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.hidden_dim, kernel_size=self.kernel, padding=\"same\", padding_mode=\"replicate\"),\n            nn.PReLU(),\n            nn.Conv2d(in_channels=self.hidden_dim, out_channels=self.output_dim, kernel_size=self.pre_post_kernel, padding=\"same\", padding_mode=\"replicate\"),\n        ]\n        self.post_layers_2 = nn.Sequential(*post_layers_2)\n\n    def forward(self, x):\n        x = self.pre_layers(x)                  # preprocess input to hidden_dim x h x w\n        x_pre = x                               # save for residual connections later\n        for block in self.blocks:               # apply residual blocks\n            x = x + block(x)\n        x = x_pre + self.post_layers_1(x)       # apply post-block skip connection\n        x = self.post_layers_2(x)               # postprocess back to c x h x w\n        return x\n\n\nclass Nearest(BaseModel):\n    \"\"\"\n    Baseline: apply nearest-neighbor upscaling from LR to HR. Because our dataloaders automatically apply\n    nearest-neighbor upscaling to ensure LR and HR are of same dimension, this model implements the identity function.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def forward(self, x):\n        return x\n\n\nclass Bilinear(BaseModel):\n    \"\"\"\n    Baseline: apply bilinear interpolation-based upscaling from LR to HR. Because our dataloaders automatically apply\n    nearest-neighbor upscaling to ensure LR and HR are of same dimension, we must first downscale then upscale\n    to use prebuilt PyTorch code.\n    \"\"\"\n    def __init__(self, pool_size, **kwargs):\n        super().__init__(**kwargs)\n        self.pool_size = pool_size\n        self.pool = nn.AvgPool2d(kernel_size=self.pool_size, stride=self.pool_size)\n\n    def forward(self, x):\n        size = x.shape[-1]\n        x = self.pool(x)    # note that x is already pooled and repeated; this changes size but does not change content\n        x = F.interpolate(x, size=size, mode=\"bilinear\")\n        return x\n\n\nclass Bicubic(BaseModel):\n    \"\"\"\n    Baseline: apply bicubic interpolation-based upscaling from LR to HR. Because our dataloaders automatically apply\n    nearest-neighbor upscaling to ensure LR and HR are of same dimension, we must first downscale then upscale\n    to use prebuilt PyTorch code.\n    \"\"\"\n    def __init__(self, pool_size, **kwargs):\n        super().__init__(**kwargs)\n        self.pool_size = pool_size\n        self.pool = nn.AvgPool2d(kernel_size=self.pool_size, stride=self.pool_size)\n\n    def forward(self, x):\n        size = x.shape[-1]\n        x = self.pool(x)  # note that x is already pooled and repeated; this changes size but does not change content\n        x = F.interpolate(x, size=size, mode=\"bicubic\")\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:37:33.369421Z","iopub.execute_input":"2021-12-08T14:37:33.370099Z","iopub.status.idle":"2021-12-08T14:37:36.133415Z","shell.execute_reply.started":"2021-12-08T14:37:33.370062Z","shell.execute_reply":"2021-12-08T14:37:36.132602Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# SRGAN Model-(keras)","metadata":{}},{"cell_type":"code","source":"class SRGAN(Basemodel):\n    def __init__(\n            self,\n            n_blocks: int = 16,         # n_blocks=16 in the paper\n            kernel: int = 3,            # k=3 in the paper\n            pre_post_kernel: int = 9,   # pre_post_kernel=9 in the paper\n            hidden_dim: int = 64,       # hidden_dim=64 in the paper\n            **kwargs\n    ):\n    \n    def res_block_gen(model, kernal_size, filters, strides):\n    \n    gen = model\n    \n    model =nn.Conv2D(in_channels= filters,out_channels=self.hidden_dim, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n    model = BatchNormalization(momentum = 0.5)(model)\n    # Using Parametric ReLU\n    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n    model = BatchNormalization(momentum = 0.5)(model)\n        \n    model = add([gen, model])\n    \n    return model\n    \n    \ndef up_sampling_block(model, kernal_size, filters, strides):\n    \n    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n    model = UpSampling2D(size = 2)(model)\n    model = LeakyReLU(alpha = 0.2)(model)\n    \n    return model\n\n\ndef discriminator_block(model, filters, kernel_size, strides):\n    \n    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n    model = BatchNormalization(momentum = 0.5)(model)\n    model = LeakyReLU(alpha = 0.2)(model)\n    \n    return model\n\n# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n\n\ndef __init__(self, noise_shape):\n\n    self.noise_shape = noise_shape\n\ndef generator(self):\n\n    gen_input = Input(shape = self.noise_shape)\n\n    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n\n    gen_model = model\n\n    # Using 16 Residual Blocks\n    for index in range(16):\n        model = res_block_gen(model, 3, 64, 1)\n\n    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n    model = BatchNormalization(momentum = 0.5)(model)\n    model = add([gen_model, model])\n\n    # Using 2 UpSampling Blocks\n    for index in range(2):\n        model = up_sampling_block(model, 3, 256, 1)\n\n    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n    model = Activation('tanh')(model)\n\n    generator_model = Model(inputs = gen_input, outputs = model)\n\n    return generator_model\n\n# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\ndef Discriminator(object):\n\ndef __init__(self, image_shape):\n\n    self.image_shape = image_shape\n\ndef discriminator(self):\n\n    dis_input = Input(shape = self.image_shape)\n\n    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n    model = LeakyReLU(alpha = 0.2)(model)\n\n    model = discriminator_block(model, 64, 3, 2)\n    model = discriminator_block(model, 128, 3, 1)\n    model = discriminator_block(model, 128, 3, 2)\n    model = discriminator_block(model, 256, 3, 1)\n    model = discriminator_block(model, 256, 3, 2)\n    model = discriminator_block(model, 512, 3, 1)\n    model = discriminator_block(model, 512, 3, 2)\n\n    model = Flatten()(model)\n    model = Dense(1024)(model)\n    model = LeakyReLU(alpha = 0.2)(model)\n\n    model = Dense(1)(model)\n    model = Activation('sigmoid')(model) \n\n    discriminator_model = Model(inputs = dis_input, outputs = model)\n\n    return discriminator_model\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Acquired","metadata":{}},{"cell_type":"code","source":"from typing import List\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport xarray as xr\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.dataloader import default_collate\nfrom matplotlib import cm\n\n\nclass ERA5Data(Dataset):\n\n    def __init__(self, datasets: List[xr.Dataset], patch_size: int, pool_size: int, pool_type: str):\n        # each element of data is an xr.Dataset representing a different physical variable\n        # in our case, data = [t2m, tp] = [temp @ 2 meters, total precipitation]\n        # we can think of each element of data as representing a different image channel\n        # we merge these channels into a single c x h x w tensor in __getitem__\n        self.datasets = datasets\n        self.patch_size = patch_size\n        self.pool_size = pool_size\n        self.pool_type = pool_type\n        self.n_channels = len(self.datasets)\n        self.n_months = datasets[0].shape[0]\n        self.n_vertical = datasets[0].shape[1] // patch_size\n        self.n_horizontal = datasets[0].shape[2] // patch_size\n        self.mus, self.stds = [], []\n        for dataset in self.datasets:\n            mu = np.nanmean(dataset.values)\n            s = np.nanstd(dataset.values)\n            dataset.values = (dataset.values - mu) / s\n            self.mus.append(mu)\n            self.stds.append(s)\n        self.mus = np.array(self.mus).reshape((1, -1, 1, 1))\n        self.stds = np.array(self.stds).reshape((1, -1, 1, 1))\n\n\n    def __len__(self):\n        return self.n_months * self.n_vertical * self.n_horizontal\n\n    def __getitem__(self, i: int):\n        # e.g., if we have 100 patches per month, then i=527 corresponds to 5th month and 527//100 = 5\n        month = i // (self.n_vertical * self.n_horizontal)\n\n        # e.g., i=527 corresponds to 27th patch in image and 527 % 100 = 27\n        patch = i % (self.n_vertical * self.n_horizontal)\n\n        # e.g., if each image is (h, w) = (5, 20) then patch 27 corresponds to 2nd row and 27 // 20 = 1\n        row = patch // self.n_horizontal\n\n        # e.g., if each image is (h, w) = (5, 20) then patch 27 corresponds to 8th col and 27 % 20 = 7\n        col = patch % self.n_horizontal\n\n        # extract patch for this month, this vertical offset, and this horizontal offset by collating channels\n        ps = self.patch_size\n        input_channels = []\n        target_channels = []\n        for c in range(self.n_channels):\n            # extract one channel at a time from self.datasets list of xr.Datasets\n            channel = self.datasets[c][month, row*ps:(row+1)*ps, col*ps:(col+1)*ps].values\n\n            # if more than half of values are nan, skip this region and return None\n            # None will be handled properly by collate_fn of DataLoader\n            if np.sum(np.isnan(channel)) > ps ** 2 / 2:\n                return None\n            # otherwise replace remaining nans with mean of region\n            else:\n                replacement = np.nanmean(channel)\n                channel = np.nan_to_num(channel, nan=replacement)\n\n            # this original full-resolution channel is the target\n            target_channels.append(channel)\n\n            # downsample and upsample to produce low-resolution input channel\n            # https://stackoverflow.com/a/42463514\n            if self.pool_type == \"mean\":\n                downsampled = channel.reshape(ps // self.pool_size, self.pool_size,\n                                              ps // self.pool_size, self.pool_size).mean(axis=(1, 3))\n            elif self.pool_type == \"max\":\n                downsampled = channel.reshape(ps // self.pool_size, self.pool_size,\n                                              ps // self.pool_size, self.pool_size).max(axis=(1, 3))\n            else:\n                raise ValueError(\"Invalid pooling type.\")\n            upsampled = np.repeat(np.repeat(downsampled, self.pool_size, axis=0), self.pool_size, axis=1)\n            input_channels.append(upsampled)\n\n        # return input x and output y for batch collation\n        input = torch.from_numpy(np.array(input_channels))\n        target = torch.from_numpy(np.array(target_channels))\n\n        return {\"x\": input, \"y\": target}\n\n    def _get_batch(self, years_per_batch, start_month=0, stop_month=None):\n        # deprecated: gets whole-geographic batch for a given number of years\n        if stop_month is None:\n            stop_month = self.n_months\n        inputs, targets = [], []\n        for month in range(start_month, stop_month):\n            for row in range(self.n_vertical):\n                for col in range(self.n_horizontal):\n                    ps = self.patch_size\n                    input_channels = []\n                    target_channels = []\n                    for c in range(self.n_channels):\n                        # extract one channel at a time from self.datasets list of xr.Datasets\n                        channel = self.datasets[c][month, row*ps:(row+1)*ps, col*ps:(col+1)*ps].values\n\n                        # if more than half of values are nan, skip this region and return None\n                        # None will be handled properly by collate_fn of DataLoader\n                        if np.sum(np.isnan(channel)) > ps**2 / 2:\n                            continue\n                        # otherwise replace remaining nans with mean of region\n                        else:\n                            replacement = np.nanmean(channel)\n                            channel = np.nan_to_num(channel, nan=replacement)\n\n                        # this original full-resolution channel is the target\n                        target_channels.append(channel)\n\n                        # downsample and upsample to produce low-resolution input channel\n                        # https://stackoverflow.com/a/42463514\n                        if self.pool_type == \"mean\":\n                            downsampled = channel.reshape(ps // self.pool_size, self.pool_size,\n                                                          ps // self.pool_size, self.pool_size).mean(axis=(1, 3))\n                        elif self.pool_type == \"max\":\n                            downsampled = channel.reshape(ps // self.pool_size, self.pool_size,\n                                                          ps // self.pool_size, self.pool_size).max(axis=(1, 3))\n                        else:\n                            raise ValueError(\"Invalid pooling type.\")\n                        upsampled = np.repeat(np.repeat(downsampled, self.pool_size, axis=0), self.pool_size, axis=1)\n                        input_channels.append(upsampled)\n\n                    # save input x and output y for batch if valid\n                    if len(input_channels) > 0:\n                        inputs.append(np.array(input_channels))\n                        targets.append(np.array(target_channels))\n\n            if (month // 12) % years_per_batch == 0:\n                # return a batch with a few years\n                input_tensor = torch.from_numpy(np.array(inputs))\n                target_tensor = torch.from_numpy(np.array(targets))\n                yield {\"x\": input_tensor, \"y\": target_tensor}\n                inputs, targets = [], []\n\n\nclass ERA5DataModule(pl.LightningDataModule):\n\n    def __init__(self, args):\n        # setup construction parameters\n        self.patch_size = args.get(\"patch_size\", 64)\n        self.pool_size = args.get(\"pool_size\", 2)\n        self.pool_type = args.get(\"pool_type\", \"mean\")\n\n        # setup data\n        self.data = xr.open_dataset(f\"../input/era5-dataset/era5.nc\")\n        self.train_start = args.get(\"train_start\", 1950)\n        self.train_end = args.get(\"train_end\", 2000)\n        self.val_start = args.get(\"val_start\", 2000)\n        self.val_end = args.get(\"val_end\", 2010)\n        self.test_start = args.get(\"test_start\", 2010)\n        self.test_end = args.get(\"test_end\", 2020)\n        train_data = [getattr(self.data, x)[12*(self.train_start - 1950):12*(self.train_end - 1950)] for x in [\"t2m\", \"tp\"]]\n        val_data = [getattr(self.data, x)[12*(self.val_start - 1950):12*(self.val_end - 1950)] for x in [\"t2m\", \"tp\"]]\n        test_data = [getattr(self.data, x)[12*(self.test_start - 1950):12*(self.test_end - 1950)] for x in [\"t2m\", \"tp\"]]\n        self.train_data = ERA5Data(train_data, self.patch_size, self.pool_size, self.pool_type)\n        self.val_data = ERA5Data(val_data, self.patch_size, self.pool_size, self.pool_type)\n        self.test_data = ERA5Data(test_data, self.patch_size, self.pool_size, self.pool_type)\n\n        # setup loader parameters\n        self.batch_size = args.get(\"batch_size\", 32)\n\n    def collate_fn(self, batch):\n        # get rid of None in minibatch arising from edges of dataset\n        # https://discuss.pytorch.org/t/questions-about-dataloader-and-dataset/806/7\n        batch = list(filter(lambda x: x is not None, batch))\n        return default_collate(batch)\n\n    def train_dataloader(self):\n        return DataLoader(self.train_data, batch_size=self.batch_size, collate_fn=self.collate_fn)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_data, batch_size=self.batch_size, collate_fn=self.collate_fn)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_data, batch_size=self.batch_size, collate_fn=self.collate_fn)\n\n    def eval_dataloader(self, pool_size):\n        # experiment with performance on non-native pool size\n        eval_data = [getattr(self.data, x)[12 * (self.test_start - 1950):12 * (self.test_end - 1950)] for x in [\"t2m\", \"tp\"]]\n        eval_data = ERA5Data(eval_data, self.patch_size, pool_size, self.pool_type)\n        return DataLoader(eval_data, batch_size=self.batch_size, collate_fn=self.collate_fn)\n\n\nif __name__ == \"__main__\":\n\n    # test entire DataModule with __getitem__ indexing\n    datamodule = ERA5DataModule(args={\"pool_size\": 4, \"batch_size\": 32})\n    dataloader = datamodule.train_dataloader()\n    fig, ax = plt.subplots(4, 4, figsize=(12, 12))\n    batch = next(iter(dataloader))\n    x = batch[\"x\"].detach().cpu().numpy()\n    y = batch[\"y\"].detach().cpu().numpy()\n    for i in range(4):\n        ax[i, 0].imshow(x[i][0], cmap=cm.RdYlBu_r); ax[i, 0].set_title(\"T2M @ LR\")\n        ax[i, 1].imshow(y[i][0], cmap=cm.RdYlBu_r); ax[i, 1].set_title(\"T2M @ HR\")\n        ax[i, 2].imshow(x[i][1], cmap=cm.BrBG); ax[i, 2].set_title(\"TP @ LR\")\n        ax[i, 3].imshow(y[i][1], cmap=cm.BrBG); ax[i, 3].set_title(\"TP @ HR\")\n    plt.tight_layout()\n    plt.show()\n\n    # test Dataset with deprecated _get_batch indexing\n    # dataset = datamodule.train_data\n    # fig, ax = plt.subplots(4, 4, figsize=(12, 12))\n    # x = next(dataset._get_batch(1))[\"x\"].detach().cpu().numpy()\n    # y = next(dataset._get_batch(1))[\"y\"].detach().cpu().numpy()\n    # for i in range(4):\n    #     ax[i, 0].imshow(x[i][0], cmap=cm.RdYlBu_r); ax[i, 0].set_title(\"T2M @ LR\")\n    #     ax[i, 1].imshow(y[i][0], cmap=cm.RdYlBu_r); ax[i, 1].set_title(\"T2M @ HR\")\n    #     ax[i, 2].imshow(x[i][1], cmap=cm.BrBG); ax[i, 2].set_title(\"TP @ LR\")\n    #     ax[i, 3].imshow(y[i][1], cmap=cm.BrBG); ax[i, 3].set_title(\"TP @ HR\")\n    # plt.tight_layout()\n    # plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T11:51:38.63221Z","iopub.execute_input":"2021-12-08T11:51:38.632463Z","iopub.status.idle":"2021-12-08T11:51:51.458145Z","shell.execute_reply.started":"2021-12-08T11:51:38.632433Z","shell.execute_reply":"2021-12-08T11:51:51.457458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 TRAIN.py","metadata":{}},{"cell_type":"code","source":"import os\nfrom argparse import ArgumentParser\n# from models import SRCNN, VDSR, SRResNet\n# from data import ERA5DataModule\nimport pytorch_lightning as pl\nimport wandb\n\n# from utils import ImageVisCallback\n\nwandb.init(project='cv-proj', entity=\"cv803f21-superres\")\n\n\ndef main(args):\n\n    # configure data module\n    e = ERA5DataModule(args={\n        \"pool_size\": args.pool_size,\n        \"batch_size\": args.batch_size,\n        \"patch_size\": args.patch_size\n    })\n    train_dl, val_dl = e.train_dataloader(), e.val_dataloader()\n\n    # input channels controls which channels we use as predictors\n    # output channels controls which channels we use as targets, i.e., loss signal\n    # channel 0 corresponds to t2m and channel 1 corresponds to tp\n    # e.g., input_channels=[0, 1], output_channels=[1] predicts tp @ HR using t2m AND tp @ LR\n    # e.g., input_channels=[1],    output_channels=[1] predicts tp @ HR using ONLY tp @ LR\n    # ...etc.\n    args.model = args.model if hasattr(args, \"model\") else \"SRCNN\"\n    if args.model.lower() == \"vdsr\":\n        print(\"Constructing VDSR\")\n        model = VDSR(input_channels=[0, 1], output_channels=[0, 1], lr=args.lr, decayRate=args.decay_Rate)\n    elif args.model.lower() == \"srresnet\":\n        print(\"Constructing SRResNet\")\n        model = SRResNet(input_channels=[0, 1], output_channels=[0, 1], lr=args.lr)\n    elif args.model.lower() == \"srcnn\":\n        print(\"Constructing SRCNN\")\n        model = SRCNN(input_channels=[0, 1], output_channels=[0, 1], lr=args.lr)\n    else:\n        raise ValueError(\"Invalid model architecture.\")\n\n    # Wandb logging\n    wandb_logger = pl.loggers.WandbLogger(project='cv-proj')\n    wandb_logger.watch(model, log_freq=500)\n\n    trainer: pl.Trainer = pl.Trainer.from_argparse_args(args)\n    trainer.logger = wandb_logger\n    trainer.callbacks.append(ImageVisCallback(val_dl))\n\n    trainer.fit(model, train_dl, val_dl)\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser()\n    parser = pl.Trainer.add_argparse_args(parser)\n    parser.add_argument('--model', default=\"SRCNN\", type=str, help=\"Model to train\")\n    parser.add_argument('--batch_size', default=128, type=int, help=\"Batch size to train with\")\n    parser.add_argument('--pool_size', default=4, type=int, help=\"Super-resolution factor\")\n    parser.add_argument('--patch_size', default=64, type=int, help=\"Image patch size to super-resolve\")\n    parser.add_argument('--lr', default=1e-3, type=float, help=\"Learning rate\")\n    parser.add_argument(\"--decay_Rate\", default=1, type=float, help=\"Exponential decay rate\")\n    args, unknown = parser.parse_known_args()\n    args.gpus=1\n    main(args)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T12:40:18.023841Z","iopub.execute_input":"2021-12-08T12:40:18.024116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.test","metadata":{}},{"cell_type":"code","source":"import argparse\nimport pytorch_lightning as pl\n# from data import ERA5DataModule\n# from models import SRCNN, VDSR, SRResNet, Nearest, Bilinear, Bicubic\n\ndef main(args):\n    e = ERA5DataModule(args={\n        \"pool_size\": args.pool_size,\n        \"batch_size\": args.batch_size,\n        \"patch_size\": args.patch_size\n    })\n    test_dl = e.test_dataloader()\n\n    if args.model.lower() == 'srcnn':\n        print(\"Testing SRCNN\")\n        model = SRCNN\n        model = model.load_from_checkpoint(args.checkpoint)\n    elif args.model.lower() == 'srresnet':\n        print(\"Testing SRResNet\")\n        model = SRResNet\n        model = model.load_from_checkpoint(args.checkpoint)\n    elif args.model.lower() == 'vdsr':\n        print(\"Testing VDSR\")\n        model = VDSR\n        model = model.load_from_checkpoint(args.checkpoint)\n    elif args.model.lower() == 'nearest':\n        print(\"Testing Nearest\")\n        model = Nearest()\n    elif args.model.lower() == 'bilinear':\n        print(\"Testing Bilinear\")\n        model = Bilinear(pool_size=args.pool_size)\n    elif args.model.lower() == 'bicubic':\n        print(\"Testing Bicubic\")\n        model = Bicubic(pool_size=args.pool_size)\n    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n\n    # Wandb logging\n    wandb_logger = pl.loggers.WandbLogger(project='cv-proj')\n    wandb_logger.watch(model, log_freq=500)\n\n    trainer: pl.Trainer = pl.Trainer.from_argparse_args(args)\n    trainer.logger = wandb_logger\n\n    trainer.test(model, test_dl)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    parser = pl.Trainer.add_argparse_args(parser)\n    parser.add_argument('--model', default=\"SRCNN\", type=str, help=\"Model to test\")\n    parser.add_argument('--checkpoint', type=str, help=\"Checkpoint file (.ckpt)\")\n    parser.add_argument('--batch_size', default=16, type=int, help=\"Batch size to train with\")\n    parser.add_argument('--pool_size', default=4, type=int, help=\"Super-resolution factor\")\n    parser.add_argument('--patch_size', default=64, type=int, help=\"Image patch size to super-resolve\")\n\n    args, unknown = parser.parse_known_args()\n    args.gpus = 1\n    # args.model = \"SRCNN\"\n    # args.checkpoint = \"cv-proj/SRCNN-lr4-lyric-tree-103-epoch=433-step=73345.ckpt\"\n    # args.model = \"VDSR\"\n    # args.checkpoint = \"cv-proj/VDSR-lr4-balmy-sound-102-epoch=86-step=14702.ckpt\"\n    # args.model = \"SRResNet\"\n    # args.checkpoint = \"cv-proj/SRResNet-lr4-robust-capybara-101-epoch=45-step=15547.ckpt\"\n\n    print(f\"Loading checkpoint {args.checkpoint}\")\n    main(args)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T11:58:15.098993Z","iopub.execute_input":"2021-12-08T11:58:15.099301Z","iopub.status.idle":"2021-12-08T11:58:15.148721Z","shell.execute_reply.started":"2021-12-08T11:58:15.099266Z","shell.execute_reply":"2021-12-08T11:58:15.146827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-08T11:58:26.010909Z","iopub.execute_input":"2021-12-08T11:58:26.011217Z","iopub.status.idle":"2021-12-08T11:58:26.055312Z","shell.execute_reply.started":"2021-12-08T11:58:26.011183Z","shell.execute_reply":"2021-12-08T11:58:26.05454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# utils","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport torch\nimport wandb\nimport pytorch_lightning as pl\n\n\nclass ImageVisCallback(pl.Callback):\n    def __init__(self, val_Dataloader, max_samples=10):\n        super().__init__()\n\n        self.valLoader = val_Dataloader\n        self.max_samples = max_samples\n\n    def on_validation_end(self, trainer: \"pl.Trainer\", model: \"pl.LightningModule\") -> None:\n        '''imgsA = self.val_imgs.to(device=model.device).unsqueeze(0)\n        imgsA = imgsA[:, model.output_channels, :, :]\n        imgsY = self.val_y.to(device=model.device).unsqueeze(0)\n        imgsY = imgsY[:, model.output_channels, :, :]\n        '''\n\n        val_dl = self.valLoader\n        dataiter = iter(val_dl)\n        for i in range(self.max_samples):\n            test = dataiter.next()\n\n            imgs = test['x'][0].to(device=model.device).unsqueeze(0)\n            imgs = imgs[:, model.output_channels, :, :]\n\n            imgsY = test['y'][0].to(device=model.device).unsqueeze(0)\n            imgsY = imgsY[:, model.output_channels, :, :]\n\n            upresed = model(imgs)\n\n            mosaics = torch.cat([imgs, upresed, imgsY], dim=-2)\n            caption = \"Image {}: Top: Low Res, Middle: High Res Prediction, Bottom: High Res Truth\".format(i)\n\n            logname = \"val/examples{}\".format(i) if os.name != \"nt\" else \"val\\examples{}\".format(i)\n            trainer.logger.experiment.log({\n                logname: [wandb.Image(mosaic, caption) for mosaic in mosaics],\n            })\n\n        trainer.logger.experiment.log({\n            \"global_step\": trainer.global_step  # This will make sure wandb gets the epoch/step right\n        })","metadata":{"execution":{"iopub.status.busy":"2021-12-08T11:52:32.892182Z","iopub.execute_input":"2021-12-08T11:52:32.892424Z","iopub.status.idle":"2021-12-08T11:52:32.902956Z","shell.execute_reply.started":"2021-12-08T11:52:32.892397Z","shell.execute_reply":"2021-12-08T11:52:32.901899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 6. eval","metadata":{}},{"cell_type":"code","source":"\nimport argparse\nimport numpy as np\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n# from data import ERA5DataModule\n# from models import SRCNN, VDSR, SRResNet, Nearest, Bilinear, Bicubic\n\n\ndef visualize_preds(dl, models, suptitle=\"Predictions\", file_name=\"preds\", save=True):\n\n    batch = list(dl.dataset._get_batch(years_per_batch=1, start_month=108))[3]\n    x = batch[\"x\"].detach().cpu().numpy() * dl.dataset.stds + dl.dataset.mus\n    y = batch[\"y\"].detach().cpu().numpy() * dl.dataset.stds + dl.dataset.mus\n    y_hats = {}\n    for model_name, model in models.items():\n        y_hats[model_name] = model(batch[\"x\"]).detach().cpu().numpy() * dl.dataset.stds + dl.dataset.mus\n\n    # extract patch indices we care about\n    patches = {\n        \"WA\": 0,\n        \"MI\": 6,\n        \"UT\": 10,\n        \"PA\": 15,\n        \"TX\": 25\n    }\n\n    fig = plt.figure(figsize=(20, 2*len(y_hats) + 4))\n    gs = fig.add_gridspec(len(y_hats) + 2, 12, width_ratios=[1]*10 + [0.1]*2)\n    \n    t2m_mins, t2m_means, t2m_maxs = [], [], []\n    tp_mins, tp_means, tp_maxs = [], [], []\n    for z in [x, y] + list(y_hats.values()):\n        t2m_mins.append(z[:, 0, :, :].min())\n        t2m_means.append(z[:, 0, :, :].mean())\n        t2m_maxs.append(z[:, 0, :, :].max())\n        tp_mins.append(z[:, 1, :, :].min())\n        tp_means.append(z[:, 1, :, :].mean())\n        tp_maxs.append(z[:, 1, :, :].max())\n    divnorm_t2m = colors.TwoSlopeNorm(vmin=min(t2m_mins), vcenter=np.mean(t2m_means), vmax=max(t2m_maxs))\n    divnorm_tp = colors.TwoSlopeNorm(vmin=min(tp_mins), vcenter=np.mean(tp_means), vmax=max(tp_maxs))\n\n    # plot images\n    all_axes = []\n    for i, (state, patch) in enumerate(patches.items()):\n        x_t2m, y_t2m = x[patch, 0], y[patch, 0]\n        y_hats_t2m = [y_hat[patch, 0] for y_hat in y_hats.values()]\n        x_tp, y_tp = x[patch, 1], y[patch, 1]\n        y_hats_tp = [y_hat[patch, 1] for y_hat in y_hats.values()]\n\n        # t2m\n        imgs = [x_t2m] + y_hats_t2m + [y_t2m]\n        axes = []\n        for j in range(len(imgs)):\n            ax = fig.add_subplot(gs[j, 2*i])\n            ax.set_xticks([])\n            ax.set_yticks([])\n            mapping_t2m = ax.imshow(imgs[j], norm=divnorm_t2m, cmap=\"RdYlBu_r\")\n            axes.append(ax)\n        all_axes.append(axes)\n\n        # tp\n        imgs = [x_tp] + y_hats_tp + [y_tp]\n        axes = []\n        for j in range(len(imgs)):\n            ax = fig.add_subplot(gs[j, 2*i + 1])\n            ax.set_xticks([])\n            ax.set_yticks([])\n            mapping_tp = ax.imshow(imgs[j], norm=divnorm_tp, cmap=\"BrBG\")\n            axes.append(ax)\n        all_axes.append(axes)\n\n    # set up titles\n    all_axes = np.array(all_axes).T\n    all_axes[0, 0].set_ylabel(\"LR Input\")\n    for i, model_name in enumerate(models.keys()):\n        all_axes[i+1, 0].set_ylabel(model_name)\n    all_axes[-1, 0].set_ylabel(\"HR Truth\")\n\n    variables = [\"T2M\", \"TP\"]\n    for i, (state, patch) in enumerate(patches.items()):\n        all_axes[0, 2*i].set_title(f\"{state} ({variables[0]})\")\n        all_axes[0, 2*i+1].set_title(f\"{state} ({variables[1]})\")\n\n    # set up colorbars\n    t2m_cax = fig.add_subplot(gs[:, -2])\n    tp_cax = fig.add_subplot(gs[:, -1])\n    fig.colorbar(mapping_t2m, cax=t2m_cax)\n    fig.colorbar(mapping_tp, cax=tp_cax)\n\n    plt.suptitle(suptitle)\n    plt.tight_layout()\n    if save:\n        plt.savefig(f\"figs/{file_name}.png\")\n    plt.show()\n\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    parser = pl.Trainer.add_argparse_args(parser)\n    parser.add_argument('--batch_size', default=128, type=int, help=\"Batch size to train with\")\n    parser.add_argument('--pool_size', default=4, type=int, help=\"Super-resolution factor\")\n    parser.add_argument('--patch_size', default=64, type=int, help=\"Image patch size to super-resolve\")\n    args = parser.parse_args()\n    args.gpus = 1\n    models = {\n        \"Nearest\": Nearest(),\n        \"Bilinear\": Bilinear(pool_size=4),\n        \"Bicubic\": Bicubic(pool_size=4),\n        \"SRCNN\": SRCNN.load_from_checkpoint(\"cv-proj/SRCNN-lr4-lyric-tree-103-epoch=433-step=73345.ckpt\"),\n        \"VDSR\": VDSR.load_from_checkpoint(\"cv-proj/VDSR-lr4-balmy-sound-102-epoch=86-step=14702.ckpt\"),\n        \"SRResNet\": SRResNet.load_from_checkpoint(\"cv-proj/SRResNet-lr4-robust-capybara-101-epoch=45-step=15547.ckpt\")\n    }\n    e = ERA5DataModule(args={\n        \"pool_size\": args.pool_size,\n        \"batch_size\": args.batch_size,\n        \"patch_size\": args.patch_size\n    })\n    test_dl = e.test_dataloader()\n\n    # test on usual 4x for April 2020\n    visualize_preds(test_dl, models, suptitle=f\"Predictions 4x (4/2020)\", file_name=f\"preds_2020_4_pool_4.png\")\n\n    # test also on 8x for April 2020\n    eval_dl_8x = e.eval_dataloader(pool_size=8)\n    models[\"Bilinear\"] = Bilinear(pool_size=8)\n    models[\"Bicubic\"] = Bilinear(pool_size=8)\n    visualize_preds(eval_dl_8x, models, suptitle=f\"Predictions 8x (4/2020)\", file_name=f\"preds_2020_4_pool_8.png\")\n\n    # test also on 16x for April 2020\n    eval_dl_16x = e.eval_dataloader(pool_size=16)\n    models[\"Bilinear\"] = Bilinear(pool_size=16)\n    models[\"Bicubic\"] = Bilinear(pool_size=16)\n    visualize_preds(eval_dl_16x, models, suptitle=f\"Predictions 16x (4/2020)\", file_name=f\"preds_2020_4_pool_16.png\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T12:04:51.627517Z","iopub.execute_input":"2021-12-08T12:04:51.627851Z","iopub.status.idle":"2021-12-08T12:04:51.681635Z","shell.execute_reply.started":"2021-12-08T12:04:51.627815Z","shell.execute_reply":"2021-12-08T12:04:51.680637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}